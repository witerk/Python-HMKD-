{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import t, norm, chi2, chi2_contingency\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font', family='Malgun Gothic')      #한글 폰트설정\n",
    "plt.rcParams['axes.unicode_minus']=False      #마이너스 부호 출력 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, scipy, sympy\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import requests, re, urllib\n",
    "\n",
    "from urllib import robotparser, request\n",
    "from urllib.request import urlopen\n",
    "import chardet\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "\n",
    "import os, sys, json\n",
    "\n",
    "import cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 레이블 인코딩(Label encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# fit( ) 과 transform( ) 으로 label 인코딩 수행\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)   #레이블 인코딩\n",
    "print('인코딩 변환값:',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print('인코딩 클래스:',encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본 값: ['TV' '냉장고' '전자레인지' '컴퓨터' '선풍기' '선풍기' '믹서' '믹서']\n"
     ]
    }
   ],
   "source": [
    "print('디코딩 원본 값:',encoder.inverse_transform([0,1,4,5,3,3,2,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫 인코딩(One-Hot encoding)\n",
    "- 원-핫 인코딩은 범주형 데이터를 처리할 때 많이 사용하는 기법으로, 각 범주를 벡터의 요소로 변환하여 해당 범주에 해당하면 1, 그렇지 않으면 0을 할당하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 5 3 3 2 2] \n",
      "\n",
      "[[0]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [3]\n",
      " [3]\n",
      " [2]\n",
      " [2]] \n",
      "\n",
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]] \n",
      "\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print(labels,'\\n')\n",
    "\n",
    "# labels는 1차원이지만, 원핫 인코더는 2차원 데이터를 입력받음\n",
    "# 데이터 변환: itmes -> 1차원 배열 -> 2차원\n",
    "labels = labels.reshape(-1, 1)\n",
    "print(labels,'\\n')\n",
    "\n",
    "# 원-핫 인코딩을 적용합니다. \n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_labels = oh_encoder.fit_transform(labels)\n",
    "\n",
    "# toarray() 함수: sparse matrix(희소행렬/ 대부분의 요소가 0인 행렬)를 \n",
    "# dense format(일반적인 2차원 배열 형태)으로 변환하는데 사용\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray(),'\\n')\n",
    "\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]] \n",
      "\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "# 2차원 ndarray로 변환합니다. \n",
    "items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "# 원-핫 인코딩을 적용합니다. \n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(items)\n",
    "oh_labels = oh_encoder.transform(items)\n",
    "\n",
    "# OneHotEncoder로 변환한 결과는 희소행렬이므로 toarray()를 이용해\n",
    "# 밀집 행렬(2차원 행렬 중 대부분의 원소가 0이 아닌)로 변환. \n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray(),'\\n')\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 후자의 경우 범주형 변수의 순서 정보가 보존된다는 점에서만 차이. 이외에 인코딩 결과 자체는 차이x\n",
    "- 리스트 -> 레이블 인코딩 -> 2차원 배열로 변환 -> 원-핫 인코딩\n",
    "- 리스트 -> 2차원 배열로 변환 -> 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items_TV</th>\n",
       "      <th>items_냉장고</th>\n",
       "      <th>items_믹서</th>\n",
       "      <th>items_선풍기</th>\n",
       "      <th>items_전자레인지</th>\n",
       "      <th>items_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   items_TV  items_냉장고  items_믹서  items_선풍기  items_전자레인지  items_컴퓨터\n",
       "0         1          0         0          0            0          0\n",
       "1         0          1         0          0            0          0\n",
       "2         0          0         0          0            1          0\n",
       "3         0          0         0          0            0          1\n",
       "4         0          0         0          1            0          0\n",
       "5         0          0         0          1            0          0\n",
       "6         0          0         1          0            0          0\n",
       "7         0          0         1          0            0          0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판다스 원핫 인코딩 함수: get_dummies()\n",
    "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "df = pd.DataFrame(items, columns=['items'])\n",
    "pd.get_dummies(df)\n",
    "\n",
    "# pd.get_dummies(items).values    #데이터프레임에 넣지 않고도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 스케일링과 정규화\n",
    "\n",
    "StandardScaler와 MinMaxScaler는 모두 scikit-learn 라이브러리의 데이터 전처리 도구입니다. 이들은 특성 스케일링(feature scaling)을 수행하는 데 사용되며, 이는 모든 특성이 동일한 스케일을 갖도록 변환하는 과정입니다. 특성의 스케일이 다르면 머신러닝 알고리즘의 성능에 부정적인 영향을 미칠 수 있습니다.\n",
    "\n",
    "#### StandardScaler\n",
    "- 이 스케일러는 특성을 표준화합니다\n",
    "- 특성의 평균을 0, 표준 편차를 1로 변경하여 정규 분포를 따르도록 만듭니다.\n",
    "- 이는 각 특성의 값에서 특성의 평균을 빼고 표준 편차로 나눔으로써 수행됩니다. 표준화는 특성의 분포가 정규 분포가 아닐 때, 또는 특성 간의 스케일 차이를 제거하려 할 때 유용합니다.\n",
    "\n",
    "#### MinMaxScaler\n",
    "- 이 스케일러는 특성을 정규화합니다\n",
    "- 특성의 최소값을 0, 최대값을 1로 변경하여 모든 특성이 0과 1 사이의 값으로 변환되도록 합니다.\n",
    "- 이는 각 특성의 값에서 특성의 최소값을 빼고, 그 결과를 특성의 범위(최대값 - 최소값)로 나눔으로써 수행됩니다. 정규화는 특성의 분포가 균등하게 퍼져 있을 때, 또는 특성의 최소값과 최대값이 명확히 정해져 있을 때 유용합니다.\n",
    "\n",
    "이 두 가지 스케일러는 모두 데이터의 분포나 값의 범위를 변경하지만, 어떤 스케일러를 사용할지는 문제의 요구 사항과 데이터의 특성에 따라 달라집니다. 또한, 이들 스케일러를 사용할 때는 항상 훈련 데이터를 기반으로 스케일러를 학습시킨 후, 이를 훈련 데이터와 테스트 데이터에 모두 적용해야 합니다. 이렇게 해야 테스트 데이터가 훈련 데이터와 동일한 방식으로 변환되므로, 모델이 일관된 입력을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<feature들의 평균 값>\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64 \n",
      "\n",
      "<feature들의 분산 값>\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 붓꽃 데이터 셋을 로딩하고 DataFrame으로 변환합니다. \n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "print('<feature들의 평균 값>')\n",
    "print(iris_df.mean(), '\\n')\n",
    "\n",
    "print('<feature들의 분산 값>')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandardScaler 사용: 평균0, 표준편차1로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<feature 들의 평균 값>\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64 \n",
      "\n",
      "<feature 들의 분산 값>\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()    #객체 생성\n",
    "\n",
    "# StandardScaler로 데이터 셋 변환. fit( ) 과 transform( ) 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform( ) -> scale 변환된 데이터 셋 -> numpy ndarry -> DataFrame\n",
    "df_scaled = pd.DataFrame(iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print('<feature 들의 평균 값>')\n",
    "print(df_scaled.mean(),'\\n')\n",
    "\n",
    "print('<feature 들의 분산 값>')\n",
    "print(df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler 사용: 최대1, 최소0으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<feature들의 최솟값>\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64 \n",
      "\n",
      "<feature들의 최댓값>\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()    #MinMaxScaler객체 생성\n",
    "\n",
    "# MinMaxScaler 로 데이터 셋 변환. fit() 과 transform() 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "#transform( ) -> scale 변환된 데이터 셋 -> numpy ndarry -> DataFrame\n",
    "df_scaled = pd.DataFrame(iris_scaled, columns=iris.feature_names)\n",
    "\n",
    "print('<feature들의 최솟값>')\n",
    "print(df_scaled.min(),'\\n')\n",
    "\n",
    "print('<feature들의 최댓값>')\n",
    "print(df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaler를 이용하여 학습/테스트 데이터에 fit(), transform(), fit_transform() 적용 시 유의사항\n",
    "- <fit 메서드>는 훈련 데이터에 대한 스케일링 파라미터(평균, 표준편차)를 계산하고, <transform 메서드>는 이 파라미터를 사용해 데이터를 실제로 변환\n",
    "- fit 메서드는 훈련 데이터에만 적용되어야 하며, 이렇게 학습된 스케일러는 훈련 데이터와 테스트 데이터에 모두 적용 (가능하면 전체 데이터에 스케일링 변환을 적용한 뒤, 학습/테스트 데이터 분리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 가상 데이터 생성\n",
    "x = np.arange(20).reshape((10,2))\n",
    "y = range(10)\n",
    "\n",
    "# 데이터를 훈련 데이터와 테스트 데이터로 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# StandarScaler 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련 데이터를 사용해 스케일러 학습\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# 스케일러를 사용해 훈련 데이터와 테스트 데이터 변환\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0 부터 10까지, 테스트 데이터는 0 부터 5까지 값을 가지는 데이터 세트로 생성\n",
    "# Scaler클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
    "train_array = np.arange(0, 11).reshape(-1, 1)\n",
    "test_array =  np.arange(0, 6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1/10 scale로 train_array 데이터 변환함. 원본 10-> 1로 변환됨.\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1/5 scale로 test_array 데이터 변환함. 원본 5->1로 변환.\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "# test_array의 scale 변환 출력.\n",
    "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "\n",
      "원본 test_array 데이터: [0 1 2 3 4 5]\n",
      "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
    "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform() 만으로 변환해야 함. \n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
    "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과제(2): 아래 animals 데이터로 원핫 인코딩을 수행한 후, 데이터프레임으로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원핫 인코딩 데이터 차원: (8, 3)\n",
      "원핫 인코딩 데이터: \n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "animals = ['고양이','개','새','개','새','새','고양이','고양이']\n",
    "\n",
    "animals = np.array(animals).reshape(-1,1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(animals)\n",
    "label = enc.transform(animals)\n",
    "\n",
    "print(f'원핫 인코딩 데이터 차원: {label.shape}')\n",
    "print(f'원핫 인코딩 데이터: \\n{label.toarray()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 레이블 인코딩 - 원핫 인코딩\n",
    "종류가 적을 땐 숫자가 작으니까 레이블인코딩으로 나눠도 되는데,\n",
    "만약 데이터 종류가 1000개쯤 되면 1~1000 사이의 숫자가 들어가서 숫자의 크기가 의미를 가지게 되므로(실제로는 아무 의미 없는데도 불구하고)<br>\n",
    "이런 경우 차라리 원핫 인코딩이 더 좋음.\n",
    "다만 원핫 인코딩은 규모가 너무 커져서 시간이 오래 걸리게 되므로, 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
