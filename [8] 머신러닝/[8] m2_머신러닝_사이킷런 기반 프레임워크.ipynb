{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917283a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import t, norm, chi2, chi2_contingency\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font', family='Malgun Gothic')      #한글 폰트설정\n",
    "plt.rcParams['axes.unicode_minus']=False      #마이너스 부호 출력 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff89597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, scipy, sympy\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import requests, re, urllib\n",
    "\n",
    "from urllib import robotparser, request\n",
    "from urllib.request import urlopen\n",
    "import chardet\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from time import sleep\n",
    "\n",
    "import os, sys, json\n",
    "\n",
    "import cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65727711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e148f5d",
   "metadata": {},
   "source": [
    "### 머신러닝\n",
    "- 데이터를 기반으로 학습하고 예측하는 알고리즘의 한 분야입니다. \n",
    "- 머신러닝은 컴퓨터가 명시적으로 프로그래밍되지 않고도 데이터에서 학습하고 예측할 수 있도록 합니다. \n",
    "- 머신러닝은 다양한 분야에서 사용되며, 학습의 핵심 사항은 다음과 같습니다.\n",
    "    - 데이터<br>: 머신러닝은 데이터를 기반으로 학습합니다. 따라서 좋은 데이터가 좋은 모델의 핵심입니다.\n",
    "    - 알고리즘<br>: 머신러닝에는 다양한 알고리즘이 있습니다. 각 알고리즘은 특정 유형의 문제에 더 적합합니다.\n",
    "    - 하이퍼파라미터<br>: 알고리즘의 성능에 영향을 미치는 매개변수를 하이퍼파라미터라고 합니다. 하이퍼파라미터는 실험을 통해 최적화해야 합니다. (모델에서 학습 중에 과대적합을 하지 않기 위해 사람이 지정해주는 것)\n",
    "    - 평가<br>: 모델의 성능을 평가하는 것은 중요합니다. 모델의 성능을 평가하는 방법에는 여러 가지가 있습니다.\n",
    "    - 배포<br>: 모델이 개발되면 배포해야 합니다. 모델을 배포하는 방법에는 여러 가지가 있습니다.\n",
    "\n",
    "### 기계 학습(ML) 학습 내용\n",
    "- 기계 학습의 기초<br>: 여기에는 기계 학습의 기본 개념, 유형(지도 학습, 비지도 학습, 반지도 학습 및 강화 학습) 및 다양한 응용 프로그램에 대한 이해가 포함됩니다.\n",
    "- 지도 학습<br>: 선형 회귀, 로지스틱 회귀, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅, SVM(Support Vector Machines) 및 k-NN(k-nearest neighbours)과 같은 알고리즘에 대해 배웁니다. 이러한 알고리즘은 레이블이 지정된 학습 데이터를 사용하여 입력 기능을 기반으로 대상 변수를 예측하는 데 사용됩니다.\n",
    "- 비지도 학습<br>: 여기에는 k-평균, 계층적 클러스터링 및 DBSCAN과 같은 클러스터링 기술에 대한 학습이 포함됩니다. 또한 PCA(Principal Component Analysis) 및 자동 인코더와 같은 차원 축소 기술에 대해서도 배웁니다.\n",
    "- 강화 학습<br>: 에이전트가 환경과 상호 작용하여 결정을 내리는 방법을 배우는 강화 학습의 기본 사항을 배웁니다.\n",
    "- 평가 지표<br>: 모델의 성능을 측정하는 방법을 이해하는 것이 중요합니다. 여기에는 정확도, 정밀도, 재현율, 분류 작업의 F1 점수, 평균 절대 오차, 회귀 작업의 평균 제곱근 오차와 같은 메트릭이 포함됩니다.\n",
    "- 신경망 및 딥러닝<br>: 신경망, 역전파 및 CNN(Convolutional Neural Networks), RNN(Recurrent Neural Networks), Long Short-Term 메모리(LSTM) 네트워크 및 트랜스포머.\n",
    "- NLP(Natural Language Processing)<br>: 인간 언어 데이터를 처리하고 이해하는 기술을 포함합니다. 주제에는 텍스트 전처리, 단어 임베딩 및 시퀀스 간 모델이 포함됩니다.\n",
    "- 데이터 전처리<br>: 누락된 데이터, 이상치 및 범주 데이터 처리를 포함하여 기계 학습을 위해 데이터를 전처리하는 기술을 다룹니다.\n",
    "- 피처 엔지니어링<br>: 기존 변수에서 새로운 변수인 파생변수를 생성하고 모델에 가장 유용한 변수를 선택하는 방법을 배웁니다.\n",
    "- 편향-분산 트레이드오프<br>: 과적합, 과소적합, 편향과 분산 사이의 균형에 대한 이해는 효과적인 모델을 구축하는 데 필수적입니다. (편향: 몰려있긴 한데 타겟에서 너무 떨어짐/ 분산: 타겟 근처긴 한데 너무 골고루 퍼져있음)\n",
    "- 정규화<br>: 과적합을 방지하기 위한 L1 및 L2 정규화와 같은 기술을 다룹니다.\n",
    "- 모델 선택 및 하이퍼파라미터 조정<br>: 교차 검증, GridSearch와 같은 기술을 포함하여 성능을 향상시키기 위해 올바른 모델을 선택하고 하이퍼파라미터를 조정하는 전략을 배우게 됩니다.\n",
    "- 기계 학습은 방대한 분야이며 기초부터 시작하여 점진적으로 지식을 확장하는 것이 좋습니다. 프로젝트를 통해 이러한 개념을 실제로 적용하는 것이 이해를 강화하는 좋은 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb28a3",
   "metadata": {},
   "source": [
    "#### 파라미터\n",
    ": 기계학습에 의해 계산되서 나오는 가중치 (모델 자체가 학습하면서 최적의 값을 찾아내는 값, 일반적으로 모델에 의해 자동으로 조정)\n",
    "#### 하이퍼 파라미터\n",
    ": 모델의 학습 과정 이전에 수동으로 조정되는 값 (ex. depth: 학습을 끝낼 깊이를 정해줌)<br>\n",
    ": 모델의 초매개변수(머신 러닝 모델의 학습 과정에 영향을 주는 값)\n",
    "<br>\n",
    "\n",
    "하이퍼 파라미터는 머신러닝에서 모델을 조절하는 \"국수 조리법\"이라고 생각하면 됩니다. 머신러닝 모델을 만들 때, 어떤 국수 재료를 사용할지, 몇 분 동안 끓일 것인지, 몇 인분을 만들 것인지 등 여러 가지 요리 조리법을 결정해야 합니다. 마찬가지로 머신러닝 모델을 만들 때도, 어떤 하이퍼 파라미터 값을 사용할지, 몇 번 반복해서 학습할지, 몇 개의 군집으로 데이터를 나눌지 등 여러 가지 하이퍼 파라미터를 결정해야 합니다. 이렇게 하이퍼 파라미터를 적절히 조절하면 더 좋은 머신러닝 모델을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52038cd",
   "metadata": {},
   "source": [
    "### 머신러닝 알고리즘\n",
    "- 크게 지도 학습, 비지도 학습, 강화 학습의 세 가지로 분류할 수 있습니다.\n",
    "- 지도 학습은 레이블이 있는 데이터를 사용하여 모델을 학습하는 방법입니다. 지도 학습 알고리즘에는 선형 회귀, 로지스틱 회귀, 의사 결정 트리, 랜덤 포레스트, 서포트 벡터 머신 등이 있습니다.\n",
    "- 비지도 학습은 레이블이 없는 데이터를 사용하여 모델을 학습하는 방법입니다. 비지도 학습 알고리즘에는 클러스터링, 차원 축소, 특징 추출 등이 있습니다.\n",
    "- 강화 학습은 에이전트가 환경과 상호 작용하여 보상을 최대화하는 방법을 학습하는 방법입니다. \n",
    "- 각 알고리즘의 로직과 기능\n",
    "    - 선형 회귀는 선형 방정식을 사용하여 데이터를 모델링하는 알고리즘입니다. 선형 회귀는 종속 변수와 독립 변수 간의 선형 관계를 예측하는 데 사용됩니다.\n",
    "    - 로지스틱 회귀는 로지스틱 함수를 사용하여 데이터를 모델링하는 알고리즘입니다. 로지스틱 회귀는 이진 분류 문제에 사용됩니다.\n",
    "    - 의사 결정 트리는 의사 결정 트리를 사용하여 데이터를 모델링하는 알고리즘입니다. 의사 결정 트리는 분류 및 회귀 문제에 사용됩니다.\n",
    "    - 랜덤 포레스트는 여러 의사 결정 트리를 결합하여 데이터를 모델링하는 알고리즘입니다. 랜덤 포레스트는 분류 및 회귀 문제에 사용됩니다.\n",
    "    - 서포트 벡터 머신은 서포트 벡터와 마진을 사용하여 데이터를 모델링하는 알고리즘입니다. 서포트 벡터 머신은 분류 및 회귀 문제에 사용됩니다.\n",
    "    - 클러스터링은 데이터를 유사한 그룹으로 그룹화하는 알고리즘입니다. 클러스터링은 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용됩니다.\n",
    "    - 차원 축소는 고차원 데이터를 저차원 공간으로 투영하는 알고리즘입니다. 차원 축소는 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용됩니다.\n",
    "    - 특징 추출은 데이터에서 새로운 특징을 추출하는 알고리즘입니다. 특징 추출은 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15c1e41",
   "metadata": {},
   "source": [
    "### 지도 학습\n",
    "- 기계 학습의 가장 일반적인 형태 중 하나이며 간단한 원리로 작동합니다.\n",
    "- 감독 학습의 원리\n",
    "    - 지도 학습에서 알고리즘은 레이블이 지정된 학습 데이터에서 학습하고 해당 데이터를 기반으로 예측을 수행합니다. \n",
    "    - 지도 학습 알고리즘은 알려진 입력 데이터 세트(특징)와 데이터에 대한 알려진 응답(대상 또는 레이블)을 취하고 모델을 훈련하여 새 데이터에 대한 응답에 대한 합리적인 예측을 생성합니다.\n",
    "- 지도 학습은 회귀 및 분류라는 두 가지 유형의 문제에 사용됩니다.\n",
    "    - 회귀: 회귀는 대상 또는 종속 변수가 연속적이거나 정렬된 전체 값일 때 사용됩니다. 회귀에 사용되는 알고리즘에는 선형 회귀, 결정 트리, 랜덤 포레스트 및 그라데이션 부스팅이 포함됩니다.\n",
    "    - 분류: 분류는 대상 변수가 범주형일 때, 간단히 말해서 입력 데이터를 범주로 분류할 때 사용합니다. 분류에 사용되는 알고리즘에는 Logistic Regression, Naive Bayes, Decision Trees, Random Forests, Support Vector Machines 및 Neural Networks가 포함됩니다.\n",
    "- 지도 학습 알고리즘이 작동하는 방식\n",
    "    - 데이터 수집: 데이터를 수집하고 전처리합니다. 데이터는 기능(입력)과 대상(출력)으로 나누어야 합니다. 이를 위해 사용되는 데이터는 출력 데이터 세트도 제공되기 때문에 레이블이 지정된 데이터라고 합니다.\n",
    "    - 모델 훈련: 알고리즘은 훈련 데이터를 통해 학습합니다. 기능과 대상 간의 패턴 또는 관계를 발견하려고 시도합니다.\n",
    "    - 모델 예측: 모델이 훈련되면 본 적이 없는 새로운 데이터의 결과를 예측하는 데 사용할 수 있습니다. 이 새 데이터에 대한 입력을 테스트 데이터라고 합니다.\n",
    "    - 평가: 모델의 예측을 실제 값과 비교하여 모델의 정확도를 평가합니다. 정확도, 정밀도, 재현율, F1 점수(분류용), 평균 절대 오차(MAE), 평균 제곱 오차(MSE), 평균 제곱근 오차(RMSE)(회귀용)와 같은 다양한 메트릭이 모델을 평가하는 데 사용됩니다.\n",
    "    - 조정: 모델의 성능이 만족스럽지 않으면 모델로 돌아가 매개변수를 조정하거나 다른 모델을 모두 선택해야 할 수 있습니다. 이 프로세스는 하이퍼파라미터 조정이라고도 합니다.\n",
    "    - 예측: 만족스러운 성능이 달성되면 이제 모델을 사용하여 보이지 않는 새로운 데이터를 예측할 수 있습니다.\n",
    "    - 활용\n",
    "- 지도 학습의 핵심 측면은 레이블이 지정된 데이터를 사용하여 모델을 훈련한다는 것입니다. 즉, 입력(기능)과 올바른 출력(레이블)이 있고 모델은 입력을 출력에 매핑하는 기능을 학습합니다. 이 함수를 학습하면 새로운 입력을 출력에 매핑하는 데 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d15cc22",
   "metadata": {},
   "source": [
    "#### 회귀\n",
    "1. 선형 회귀 (Linear Regression)\n",
    "종속 변수와 한 개 이상의 독립 변수 간의 선형 관계를 모델링하는 회귀 분석 알고리즘<br>\n",
    "예측 결과를 비교할 때, \"예측 값과 실제 값의 차이를 최소화\"하는 최적의 선형 함수를 찾는 것이 목표입니다.<br>\n",
    "주로 연속적인 수치 값을 예측할 때 사용합니다.\n",
    "2. 결정 트리 (Decision Tree)\n",
    "데이터의 분류나 예측 문제를 해결하기 위한 분류 및 회귀 분석에 사용되는 지도 학습 알고리즘입니다.<br>\n",
    "데이터를 분할하여 \"최적의 분할\"을 결정하고, 이를 반복하여 \"분류 규칙\"을 구성<br>\n",
    "이해하기 쉽고 시각적으로 표현하기 좋으며, 비교적 높은 예측 성능을 가지고 있습니다.\n",
    "3. 랜덤 포레스트 (Random Forest)\n",
    "여러 개의 결정 트리를 만들어 그 결과를 \"앙상블\"하는 알고리즘입니다.<br>\n",
    "데이터의 \"일부 샘플과 변수를 랜덤으로 선택\"하여 각각의 결정 트리를 생성하고, 이를 평균화하여 예측 결과를 도출합니다.<br>\n",
    "과적합을 방지하고, 예측 성능을 높이는 데 효과적입니다.\n",
    "4. 그라데이션 부스팅 (Gradient Boosting)\n",
    "여러 개의 결정 트리를 만들어 그 결과를 \"앙상블\"하는 알고리즘입니다.<br>\n",
    "\"이전 모델의 잔여 오차\"를 새로운 모델이 예측하는 방식으로 이전 모델의 \"오류를 개선\"해나가는 방식입니다.<br>\n",
    "과적합을 방지하고, 예측 성능을 높이는 데 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9be7d",
   "metadata": {},
   "source": [
    "### 비지도학습\n",
    "- 비지도 학습(Unsupervised Learning)은 레이블이 지정되지 않은 데이터를 사용하여 모델을 학습하는 방법입니다. \n",
    "- 지도 학습과 달리 비지도 학습은 모델의 성능을 평가하기 위한 레이블이 필요하지 않습니다. \n",
    "- 비지도 학습 알고리즘\n",
    "    - 클러스터링: 클러스터링은 유사한 데이터 포인트를 그룹화하는 작업입니다. 클러스터링은 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용됩니다.\n",
    "    - 차원 축소: 차원 축소는 고차원 데이터를 저차원 공간으로 투영하는 작업입니다. 차원 축소는 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용됩니다.\n",
    "    - 특징 추출: 특징 추출은 데이터에서 새로운 특징을 추출하는 작업입니다. 특징 추출은 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용됩니다.\n",
    "- 비지도 학습은 다음과 같은 다양한 알고리즘을 사용하여 수행할 수 있습니다.\n",
    "    - 클러스터링: 클러스터링 알고리즘에는 K-평균, 평균-점 클러스터링, DBSCAN 등이 있습니다.\n",
    "    - 차원 축소: 차원 축소 알고리즘에는 주성분 분석(PCA), 차원 축소, 비지도 특징 추출 등이 있습니다.\n",
    "    - 특징 추출: 특징 추출 알고리즘에는 주성분 분석(PCA), 선형 변환, 비선형 변환 등이 있습니다.\n",
    "- 비지도 학습은 머신 러닝에서 강력한 도구입니다. 비지도 학습은 데이터를 이해하고 데이터에서 패턴을 찾는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f618d49",
   "metadata": {},
   "source": [
    "### 사이킷런\n",
    "- 사이킷런(scikit-learn)은 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리입니다. \n",
    "- 사이킷런은 파이썬 기반의 머신러닝을 위한 가장 쉽고 효율적인 개발 라이브러리를 제공합니다.\n",
    "\n",
    "- 사이킷런의 특징\n",
    "    - 파이썬 기반의 다른 머신러닝 패키지도 사이킷런 스타일의 API를 지향할 정도로 쉽고 가장 파이썬스러운 API를 제공합니다.\n",
    "    - 머신러닝을 위한 매우 다양한 알고리즘과 개발을 위한 편리한 프레임워크와 API를 제공합니다.\n",
    "    - 많은 머신러닝 알고리즘이 효율적으로 구현되어 있기에 머신러닝을 처음 배울 때 사용하기 매우 좋습니다.\n",
    "    - 사이킷런은 오픈 소스 라이브러리이기 때문에 누구나 자유롭게 사용할 수 있습니다.\n",
    "    - 사이킷런은 다음과 같은 다양한 머신러닝 알고리즘을 제공합니다.\n",
    "        - 분류\n",
    "        - 회귀\n",
    "        - 클러스터링\n",
    "        - 차원 축소\n",
    "        - 특징 추출\n",
    "        - 모델 선택 및 평가\n",
    "    - 사이킷런은 또한 다음과 같은 다양한 프레임워크와 API를 제공합니다.\n",
    "        - 데이터 전처리\n",
    "        - 모델 학습 및 예측\n",
    "        - 모델 저장 및 복원\n",
    "        - 모델 모니터링\n",
    "        - 모델 배포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36cf55",
   "metadata": {},
   "source": [
    "### Python의 기계 학습 라이브러리인 Scikit-Learn을 효과적으로 이해하기 위해 배워야 할 주요 사항\n",
    "\n",
    "- Python 프로그래밍: Scikit-Learn은 Python 라이브러리이므로 Python 숙련도가 중요합니다. 여기에는 데이터 유형, 제어 흐름, 기능 이해 및 패키지 작업이 포함됩니다.\n",
    "- 데이터 구조: 목록, 사전 및 집합과 같은 Python의 기본 데이터 구조를 이해하는 것이 중요합니다. 데이터 분석 라이브러리인 Pandas는 특히 DataFrames와 함께 Scikit-Learn에서 사용할 데이터 조작에 필수적입니다.\n",
    "- NumPy 및 Matplotlib: Scikit-Learn은 숫자 데이터를 효율적으로 처리하는 데 사용되는 NumPy 배열과 잘 작동합니다. 플로팅 라이브러리인 Matplotlib는 데이터를 시각화하고 결과를 모델링하는 데 사용됩니다.\n",
    "- 기본 통계 및 확률: 이들은 기계 학습의 빌딩 블록입니다. 주요 개념에는 평균, 중앙값, 모드, 표준 편차, 확률 분포, 가설 테스트 및 상관 계수가 포함됩니다.\n",
    "- 머신 러닝 개념: 지도 학습, 비지도 학습, 강화 학습 등 머신 러닝의 기본 사항을 숙지합니다. 회귀, 분류, 클러스터링, 차원 감소 및 앙상블 방법과 같은 일반적인 알고리즘 및 개념을 이해합니다.\n",
    "- Scikit-Learn API: Scikit-Learn API와 일관된 인터페이스를 이해하는 것이 중요합니다. 여기에는 라이브러리를 가져오고, 모델을 만들고, 모델을 데이터에 맞추고, 새 데이터 포인트를 예측하고, 모델의 성능을 평가하는 방법을 아는 것이 포함됩니다.\n",
    "- 데이터 전처리: 크기 조정, 정규화, 범주형 변수 인코딩 및 누락된 값 처리를 위한 Scikit-Learn의 전처리 도구를 사용하는 방법을 배웁니다.\n",
    "- 모델 평가 및 조정: 교차 검증, 혼동 행렬, ROC 곡선, 정밀도, 재현율, F1 점수 등과 같은 모델 평가를 위한 Scikit-Learn 도구를 사용하는 방법을 이해합니다. GridSearch(하이퍼파라미터 최적화) 및 RandomizedSearch와 같은 기술을 사용하여 모델을 조정하는 방법을 알아보세요.\n",
    "- 파이프라인 생성: Scikit-Learn은 전처리 및 모델 교육 프로세스를 간소화하는 파이프라인을 생성하는 유틸리티를 제공합니다. 이것은 효율적이고 재현 가능한 코드를 만들기 위해 배워야 할 중요한 측면입니다.\n",
    "- 딥 러닝: Scikit-Learn은 주로 딥 러닝에 사용되지 않지만 알아두면 유용할 수 있는 신경망에 대한 일부 지원을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e844b81",
   "metadata": {},
   "source": [
    "### 사이킷런의 주요 모듈\n",
    "- model_selection: 학습 데이터와 테스트 데이터를 분리하거나 교차 검증, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위해서 다양한 함수와 클래스를 제공합니다.\n",
    "- preprocessing: 데이터를 정규화(스탠다드 스케일러, Min-Max 스케일러 등), 스케일링, 인코딩하는 등 다양한 기능을 제공합니다.\n",
    "- datasets: 다양한 데이터 세트를 제공합니다.\n",
    "- linear_model: 선형 회귀, 로지스틱 회귀, 릿지 회귀, 라쏘 회귀 등 다양한 선형 모델을 제공합니다.\n",
    "- tree: 의사 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리 등 다양한 트리 기반 모델을 제공합니다.\n",
    "- svm: 서포트 벡터 머신, 커널 서포트 벡터 머신 등 다양한 서포트 벡터 머신을 제공합니다.\n",
    "- neighbors: K-최근접 이웃 알고리즘을 제공합니다.\n",
    "- ensemble: 앙상블 방법을 제공합니다.\n",
    "- cluster: 클러스터링 알고리즘을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b789e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b7fc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 셋 key들:  dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "keys = data.keys()\n",
    "print('붓꽃 데이터 셋 key들: ',keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb8d0431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names의 type:  <class 'list'>\n",
      "feature_names의 shape:  4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] \n",
      "\n",
      "target_names의 type:  <class 'numpy.ndarray'>\n",
      "target_names의 shape:  3\n",
      "['setosa' 'versicolor' 'virginica'] \n",
      "\n",
      "target의 type:  <class 'numpy.ndarray'>\n",
      "target의 shape:  (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2] \n",
      "\n",
      "data의 type:  <class 'numpy.ndarray'>\n",
      "data의 shape:  150\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 변수들의 종류\n",
    "print('feature_names의 type: ',type(data.feature_names))\n",
    "print('feature_names의 shape: ',len(data.feature_names))\n",
    "print(data.feature_names,'\\n')\n",
    "\n",
    "# target 내 각각의 이름\n",
    "print('target_names의 type: ',type(data.target_names))\n",
    "print('target_names의 shape: ',len(data.target_names))\n",
    "print(data.target_names,'\\n')\n",
    "\n",
    "# target 데이터가 어떻게 구성돼 있는지\n",
    "print('target의 type: ',type(data.target))\n",
    "print('target의 shape: ',data.target.shape)\n",
    "print(data.target,'\\n')\n",
    "\n",
    "print('data의 type: ',type(data.data))\n",
    "print('data의 shape: ',len(data.data))\n",
    "print(data.data,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffa322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022ba94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc621c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
