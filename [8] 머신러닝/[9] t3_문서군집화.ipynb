{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0c6bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random, re, time, xgboost, glob, os, nltk, string\n",
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "#맷플랏립 그래프 주피터에서 바로 출력하기\n",
    "from matplotlib import rc\n",
    "rc('font', family='Malgun Gothic')      #한글 폰트설정\n",
    "plt.rcParams['axes.unicode_minus']=False      #마이너스 부호 출력 설정\n",
    "\n",
    "from scipy import stats, sparse\n",
    "from scipy.stats import t, norm, chi2, chi2_contingency, skew\n",
    "from sklearn.datasets import load_iris, make_classification, load_breast_cancer, load_boston, make_blobs, fetch_20newsgroups\n",
    "from sklearn import datasets, tree\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, Binarizer, PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "    recall_score, confusion_matrix, f1_score, classification_report,\\\n",
    "    precision_recall_curve, roc_auc_score, mean_squared_error, r2_score,\\\n",
    "    mean_absolute_error, silhouette_samples, silhouette_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, \\\n",
    "    GradientBoostingClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import plot_importance, XGBClassifier, XGBRegressor\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, NMF\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da11a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, string, nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e069288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "\n",
       "                                        opinion_text  \n",
       "0                                                ...  \n",
       "1                                                ...  \n",
       "2                                                ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "path = r'D:\\hmkd1\\dataset\\OpinosisDataset1.0\\topics'\n",
    "all_files = glob.glob(os.path.join(path,'*.data'))\n",
    "# topics 아래 모든 \".data\" 파일들의 이름을 리스트로 취합\n",
    "\n",
    "filename_list = []   #개별 파일들의 파일명을 리스트로 취합\n",
    "opinion_text = []   #내용은 DF로딩 후 다시 string로 변환\n",
    "\n",
    "for i in all_files:\n",
    "    df = pd.read_table(i, index_col=None, header=0, encoding='latin1')\n",
    "    \n",
    "    #경로로 된 파일명 가공\n",
    "    filename_ = i.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "    \n",
    "    filename_list.append(filename)   #파일명\n",
    "    opinion_text.append(df.to_string())   #파일 내용\n",
    "    \n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "document_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5a0247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b2e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk, string\n",
    "\n",
    "remove_punct_dict = dict((ord(i), None) for i in string.punctuation)\n",
    "# string.punctuation: 모든 특수문자 포함(., ?, !, (, ) 등)\n",
    "# ord(i): 해당 문자의 유니코드 코드 포인트\n",
    "# ㄴ이걸 키로 해서, 값은 none으로 저장해둠\n",
    "lemmar = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037d78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력된 단어들에 대해 어근 형태로 변환(lemmatization)\n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(t) for t in tokens]\n",
    "\n",
    "# 입력 문장-> stop words 제거-> 소문자 변환-> 단어 토큰화-> 어근 변환\n",
    "def LemNormalize(text):\n",
    "    text = text.lower()  #소문자변환\n",
    "    text = text.translate(remove_punct_dict)   #구두점문자(모든 특수문자) 제거\n",
    "    text = nltk.word_tokenize(text)   #단어 토큰화\n",
    "    return LemTokens(text)   #어근변환 사용자함수\n",
    "#-------------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 영어 stop words 제거\n",
    "# LemNormalize사용자 함수(소문자변환, 구두점문자 제거, 단어토큰화, 어근변환)\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english',\n",
    "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdcc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature vectorization(텍스트 데이터를 수치형 벡터로 변환하는 과정)\n",
    "# document_df.opinion_text에 적용\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4bd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 군집화(5개)\n",
    "km_c = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
    "km_c.fit(feature_vect)   # 51x4611 shape\n",
    "\n",
    "cluster_label = km_c.labels_\n",
    "cluster_centers = km_c.cluster_centers_  #각 클러스터 중심점(각 피처별 5개씩, 5x4611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9266e640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "0   accuracy_garmin_nuvi_255W_gps   \n",
       "1  bathroom_bestwestern_hotel_sfo   \n",
       "2      battery-life_amazon_kindle   \n",
       "\n",
       "                                        opinion_text  cluster_label  \n",
       "0                                                ...              2  \n",
       "1                                                ...              0  \n",
       "2                                                ...              1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5c5f84e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>room_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rooms_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rooms_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename  \\\n",
       "1   bathroom_bestwestern_hotel_sfo   \n",
       "32         room_holiday_inn_london   \n",
       "30     rooms_bestwestern_hotel_sfo   \n",
       "31         rooms_swissotel_chicago   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "1                                                 ...              0  \n",
       "32                                                ...              0  \n",
       "30                                                ...              0  \n",
       "31                                                ...              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==0].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d8015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>battery-life_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>battery-life_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>battery-life_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>keyboard_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>performance_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>size_asus_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sound_ipod_nano_8gb</td>\n",
       "      <td>headphone jack i got a clear case for it a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>speed_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  \\\n",
       "2    battery-life_amazon_kindle   \n",
       "3    battery-life_ipod_nano_8gb   \n",
       "4   battery-life_netbook_1005ha   \n",
       "19      keyboard_netbook_1005ha   \n",
       "26   performance_netbook_1005ha   \n",
       "41     size_asus_netbook_1005ha   \n",
       "42          sound_ipod_nano_8gb   \n",
       "44               speed_windows7   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "2                                                 ...              1  \n",
       "3                                                 ...              1  \n",
       "4                                                 ...              1  \n",
       "19                                                ...              1  \n",
       "26                                                ...              1  \n",
       "41                                                ...              1  \n",
       "42      headphone jack i got a clear case for it a...              1  \n",
       "44                                                ...              1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==1].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994565a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>buttons_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>directions_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>display_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eyesight-issues_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>features_windows7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fonts_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>navigation_amazon_kindle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>satellite_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>screen_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>screen_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>screen_netbook_1005ha</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>speed_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>updates_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>video_ipod_nano_8gb</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>voice_garmin_nuvi_255W_gps</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  \\\n",
       "0     accuracy_garmin_nuvi_255W_gps   \n",
       "5             buttons_amazon_kindle   \n",
       "8   directions_garmin_nuvi_255W_gps   \n",
       "9      display_garmin_nuvi_255W_gps   \n",
       "10    eyesight-issues_amazon_kindle   \n",
       "11                features_windows7   \n",
       "12              fonts_amazon_kindle   \n",
       "23         navigation_amazon_kindle   \n",
       "33   satellite_garmin_nuvi_255W_gps   \n",
       "34      screen_garmin_nuvi_255W_gps   \n",
       "35             screen_ipod_nano_8gb   \n",
       "36            screen_netbook_1005ha   \n",
       "43       speed_garmin_nuvi_255W_gps   \n",
       "48     updates_garmin_nuvi_255W_gps   \n",
       "49              video_ipod_nano_8gb   \n",
       "50       voice_garmin_nuvi_255W_gps   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "0                                                 ...              2  \n",
       "5                                                 ...              2  \n",
       "8                                                 ...              2  \n",
       "9                                                 ...              2  \n",
       "10                                                ...              2  \n",
       "11                                                ...              2  \n",
       "12                                                ...              2  \n",
       "23                                                ...              2  \n",
       "33                                                ...              2  \n",
       "34                                                ...              2  \n",
       "35                                                ...              2  \n",
       "36                                                ...              2  \n",
       "43                                                ...              2  \n",
       "48                                                ...              2  \n",
       "49                                                ...              2  \n",
       "50                                                ...              2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==2].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e071a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>food_holiday_inn_london</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>food_swissotel_chicago</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>free_bestwestern_hotel_sfo</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  \\\n",
       "13     food_holiday_inn_london   \n",
       "14      food_swissotel_chicago   \n",
       "15  free_bestwestern_hotel_sfo   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "13                                                ...              3  \n",
       "14                                                ...              3  \n",
       "15                                                ...              3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==3].sort_values(by='filename').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc705f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comfort_honda_accord_2008</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comfort_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gas_mileage_toyota_camry_2007</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  \\\n",
       "6       comfort_honda_accord_2008   \n",
       "7       comfort_toyota_camry_2007   \n",
       "16  gas_mileage_toyota_camry_2007   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "6                                                 ...              4  \n",
       "7                                                 ...              4  \n",
       "16                                                ...              4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==4].sort_values(by='filename').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce26a87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 중심 개수가 약간 많게 설정돼 있어서 세분화되어 군집화 \n",
    "# -> 중심 개수를 3개로 조정\n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "\n",
    "document_df['cluster_label'] = cluster_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5e36c",
   "metadata": {},
   "source": [
    "### 군집(cluster)별 핵심 단어 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86644659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_centers shape : (3, 4611)\n",
      "[[0.01005322 0.         0.         ... 0.00706287 0.         0.        ]\n",
      " [0.         0.00092551 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00099499 0.00174637 ... 0.         0.00183397 0.00144581]]\n"
     ]
    }
   ],
   "source": [
    "print('cluster_centers shape :',cluster_centers.shape)\n",
    "print(cluster_centers)\n",
    "# 3개 군집, 4611개의 word(피처)\n",
    "# 각 군집내 피처들이 개별 중심과 얼마나 가까운지\n",
    "# 0~1사이 값, 1에 가까울수록 중심과 가까운 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b719dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 핵심단어, 단어의 중심 위치 상대값, 대상 파일명 반환\n",
    "def get_cluster_details(cluster_model, cluster_data, \n",
    "            feature_names, clusters_num, top_n_features=10):\n",
    "    cluster_details = {}\n",
    "    \n",
    "    # 군집중심점(centroid)별 피처들의 거리값이 큰 순 -> 인덱스 저장\n",
    "    # argsort: 오름차순 정렬 -> [:,::-1]: 뒤집어서 내림차순 정렬\n",
    "    ct_ind = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
    "    \n",
    "    #개별 군집별 반복(핵심단어, 중심 위치 상대값, 대상 파일명 입력)\n",
    "    for c_num in range(clusters_num):\n",
    "        cluster_details[c_num] = {}\n",
    "        cluster_details[c_num]['cluster'] = c_num  #군집 번호\n",
    "        \n",
    "        # ct_ind 인덱스를 이용하여 top n 피처 단어 구함\n",
    "        top_feature_indexes = ct_ind[c_num, :top_n_features]\n",
    "        top_features = [ feature_names[i] for i in top_feature_indexes ]\n",
    "        \n",
    "        # top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함 \n",
    "        top_feature_values = cluster_model.cluster_centers_[c_num, top_feature_indexes].tolist()\n",
    "        \n",
    "        # cluster_details 딕셔너리 객체에 개별 군집별 핵심 단어와 중심위치 상대값, 그리고 해당 파일명 입력\n",
    "        cluster_details[c_num]['top_features'] = top_features\n",
    "        cluster_details[c_num]['top_features_value'] = top_feature_values\n",
    "        filenames = cluster_data[cluster_data['cluster_label'] == c_num]['filename']\n",
    "        filenames = filenames.values.tolist()\n",
    "        cluster_details[c_num]['filenames'] = filenames\n",
    "        \n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a5e7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_details(cluster_details):\n",
    "    for c_num, c_detail in cluster_details.items():\n",
    "        print(f\"##### Cluster {c_num}\")\n",
    "        print(f\"Top teatures {c_detail['top_features']}\")\n",
    "        print(f\"Reviews 파일명 {c_detail['filenames'][:7]}\")\n",
    "        print(f\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfa55a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Cluster 0\n",
      "Top teatures ['screen', 'battery', 'keyboard', 'battery life', 'life', 'kindle', 'direction', 'video', 'size', 'voice']\n",
      "Reviews 파일명 ['accuracy_garmin_nuvi_255W_gps', 'battery-life_amazon_kindle', 'battery-life_ipod_nano_8gb', 'battery-life_netbook_1005ha', 'buttons_amazon_kindle', 'directions_garmin_nuvi_255W_gps', 'display_garmin_nuvi_255W_gps']\n",
      "===========================\n",
      "##### Cluster 1\n",
      "Top teatures ['interior', 'seat', 'mileage', 'comfortable', 'gas', 'gas mileage', 'transmission', 'car', 'performance', 'quality']\n",
      "Reviews 파일명 ['comfort_honda_accord_2008', 'comfort_toyota_camry_2007', 'gas_mileage_toyota_camry_2007', 'interior_honda_accord_2008', 'interior_toyota_camry_2007', 'mileage_honda_accord_2008', 'performance_honda_accord_2008']\n",
      "===========================\n",
      "##### Cluster 2\n",
      "Top teatures ['room', 'hotel', 'service', 'staff', 'food', 'location', 'bathroom', 'clean', 'price', 'parking']\n",
      "Reviews 파일명 ['bathroom_bestwestern_hotel_sfo', 'food_holiday_inn_london', 'food_swissotel_chicago', 'free_bestwestern_hotel_sfo', 'location_bestwestern_hotel_sfo', 'location_holiday_inn_london', 'parking_bestwestern_hotel_sfo']\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_vect.get_feature_names()\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\\\n",
    "                                  feature_names=feature_names, clusters_num=3, top_n_features=10 )\n",
    "\n",
    "print_cluster_details(cluster_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770bb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57376a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2be3f53e",
   "metadata": {},
   "source": [
    "### Opinion Review 데이터 세트를 이용한 문서 군집화 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88856b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, opinion_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', 700)\n",
    "\n",
    "# 아래는 제 컴퓨터에서 압축 파일을 풀어 놓은 디렉터리이니, 여러분의 디렉터리를 설정해 주세요  \n",
    "path = r'D:\\hmkd1\\dataset\\OpinosisDataset1.0\\topics'\n",
    "# path로 지정한 디렉터리 밑에 있는 모든 .data 파일들의 파일명을 리스트로 취합\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))    \n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "# 개별 파일들의 파일명은 filename_list 리스트로 취합, \n",
    "# 개별 파일들의 파일 내용은 DataFrame 로딩 후 다시 string으로 변환하여 opinion_text 리스트로 취합 \n",
    "for file_ in all_files:\n",
    "    # 개별 파일을 읽어서 DataFrame으로 생성 \n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    \n",
    "    # 절대경로로 주어진 file 명을 가공. 만일 Linux에서 수행시에는 아래 \\\\를 / 변경. \n",
    "    # 맨 마지막 .data 확장자도 제거\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "\n",
    "    # 파일명 리스트와 파일 내용 리스트에 파일명과 파일 내용을 추가. \n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "# 파일명 리스트와 파일 내용 리스트를  DataFrame으로 생성\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7875569",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer의 tokenizer인자로 사용될 lemmatization 어근 변환 함수를 설정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce223411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()\n",
    "\n",
    "# 입력으로 들어온 token단어들에 대해서 lemmatization 어근 변환. \n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "# TfidfVectorizer 객체 생성 시 tokenizer인자로 해당 함수를 설정하여 lemmatization 적용\n",
    "# 입력으로 문장을 받아서 stop words 제거-> 소문자 변환 -> 단어 토큰화 -> lemmatization 어근 변환. \n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56196b01",
   "metadata": {},
   "source": [
    "### TF-IDF 기반 Vectorization 적용 및 KMeans 군집화 수행. \n",
    "* Stemming과 Lemmatization 같은 어근 변환은 TfidfVectorizer에서 직접 지원하진 않으나 tokenizer 파라미터에 커스텀 어근 변환 함수를 적용하여 어근 변환을 수행할 수 있음\n",
    "* TfidfVectorizer 생성자의 tokenizer인자로 위에서 생성 LemNormalize 함수 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc28b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \\\n",
    "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )\n",
    "\n",
    "#opinion_text 컬럼값으로 feature vectorization 수행\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda8f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 5개 집합으로 군집화 수행. 예제를 위해 동일한 클러스터링 결과 도출용 random_state=0 \n",
    "km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df50773",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317eebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label']==0].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999146c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label']==1].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label']==2].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label']==3].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label']==4].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fb3ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 3개의 집합으로 군집화 \n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "\n",
    "\n",
    "# 소속 클러스터를 cluster_label 컬럼으로 할당하고 cluster_label 값으로 정렬\n",
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.sort_values(by='cluster_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b683ad",
   "metadata": {},
   "source": [
    "### 군집(Cluster)별 핵심 단어 추출하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb784b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = km_cluster.cluster_centers_\n",
    "print('cluster_centers shape :',cluster_centers.shape)\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9018ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 top n 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명들을 반환함. \n",
    "def get_cluster_details(cluster_model, cluster_data, feature_names, clusters_num, top_n_features=10):\n",
    "    cluster_details = {}\n",
    "    \n",
    "    # cluster_centers array 의 값이 큰 순으로 정렬된 index 값을 반환\n",
    "    # 군집 중심점(centroid)별 할당된 word 피처들의 거리값이 큰 순으로 값을 구하기 위함.  \n",
    "    centroid_feature_ordered_ind = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
    "    \n",
    "    #개별 군집별로 iteration하면서 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명 입력\n",
    "    for cluster_num in range(clusters_num):\n",
    "        # 개별 군집별 정보를 담을 데이터 초기화. \n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
    "        \n",
    "        # cluster_centers_.argsort()[:,::-1] 로 구한 index 를 이용하여 top n 피처 단어를 구함. \n",
    "        top_feature_indexes = centroid_feature_ordered_ind[cluster_num, :top_n_features]\n",
    "        top_features = [ feature_names[ind] for ind in top_feature_indexes ]\n",
    "        \n",
    "        # top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함 \n",
    "        top_feature_values = cluster_model.cluster_centers_[cluster_num, top_feature_indexes].tolist()\n",
    "        \n",
    "        # cluster_details 딕셔너리 객체에 개별 군집별 핵심 단어와 중심위치 상대값, 그리고 해당 파일명 입력\n",
    "        cluster_details[cluster_num]['top_features'] = top_features\n",
    "        cluster_details[cluster_num]['top_features_value'] = top_feature_values\n",
    "        filenames = cluster_data[cluster_data['cluster_label'] == cluster_num]['filename']\n",
    "        filenames = filenames.values.tolist()\n",
    "        cluster_details[cluster_num]['filenames'] = filenames\n",
    "        \n",
    "    return cluster_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f08229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_details(cluster_details):\n",
    "    for cluster_num, cluster_detail in cluster_details.items():\n",
    "        print('####### Cluster {0}'.format(cluster_num))\n",
    "        print('Top features:', cluster_detail['top_features'])\n",
    "        print('Reviews 파일명 :',cluster_detail['filenames'][:7])\n",
    "        print('==================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\\\n",
    "                                  feature_names=feature_names, clusters_num=3, top_n_features=10 )\n",
    "print_cluster_details(cluster_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad2437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c823f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Opinion Review 데이터 세트를 이용한 문서 군집화 수행하기\n",
    "\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', 700)\n",
    "\n",
    "# 아래는 제 컴퓨터에서 압축 파일을 풀어 놓은 디렉터리이니, 여러분의 디렉터리를 설정해 주세요  \n",
    "path = r'C:\\Users\\chkwon\\Text\\OpinosisDataset1.0\\OpinosisDataset1.0\\topics'\n",
    "# path로 지정한 디렉터리 밑에 있는 모든 .data 파일들의 파일명을 리스트로 취합\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))    \n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "# 개별 파일들의 파일명은 filename_list 리스트로 취합, \n",
    "# 개별 파일들의 파일 내용은 DataFrame 로딩 후 다시 string으로 변환하여 opinion_text 리스트로 취합 \n",
    "for file_ in all_files:\n",
    "    # 개별 파일을 읽어서 DataFrame으로 생성 \n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    \n",
    "    # 절대경로로 주어진 file 명을 가공. 만일 Linux에서 수행시에는 아래 \\\\를 / 변경. \n",
    "    # 맨 마지막 .data 확장자도 제거\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "\n",
    "    # 파일명 리스트와 파일 내용 리스트에 파일명과 파일 내용을 추가. \n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "# 파일명 리스트와 파일 내용 리스트를  DataFrame으로 생성\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "document_df.head()\n",
    "\n",
    "#### TfidfVectorizer의 tokenizer인자로 사용될 lemmatization 어근 변환 함수를 설정. \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()\n",
    "\n",
    "# 입력으로 들어온 token단어들에 대해서 lemmatization 어근 변환. \n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "# TfidfVectorizer 객체 생성 시 tokenizer인자로 해당 함수를 설정하여 lemmatization 적용\n",
    "# 입력으로 문장을 받아서 stop words 제거-> 소문자 변환 -> 단어 토큰화 -> lemmatization 어근 변환. \n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "### TF-IDF 기반 Vectorization 적용 및 KMeans 군집화 수행. \n",
    "* Stemming과 Lemmatization 같은 어근 변환은 TfidfVectorizer에서 직접 지원하진 않으나 tokenizer 파라미터에 커스텀 어근 변환 함수를 적용하여 어근 변환을 수행할 수 있음\n",
    "* TfidfVectorizer 생성자의 tokenizer인자로 위에서 생성 LemNormalize 함수 설정.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \\\n",
    "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )\n",
    "\n",
    "#opinion_text 컬럼값으로 feature vectorization 수행\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 5개 집합으로 군집화 수행. 예제를 위해 동일한 클러스터링 결과 도출용 random_state=0 \n",
    "km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "\n",
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.head()\n",
    "\n",
    "document_df[document_df['cluster_label']==0].sort_values(by='filename')\n",
    "\n",
    "document_df[document_df['cluster_label']==1].sort_values(by='filename')\n",
    "\n",
    "document_df[document_df['cluster_label']==2].sort_values(by='filename')\n",
    "\n",
    "document_df[document_df['cluster_label']==3].sort_values(by='filename')\n",
    "\n",
    "document_df[document_df['cluster_label']==4].sort_values(by='filename')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 3개의 집합으로 군집화 \n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "\n",
    "\n",
    "# 소속 클러스터를 cluster_label 컬럼으로 할당하고 cluster_label 값으로 정렬\n",
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.sort_values(by='cluster_label')\n",
    "\n",
    "### 군집(Cluster)별 핵심 단어 추출하기\n",
    "\n",
    "\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "print('cluster_centers shape :',cluster_centers.shape)\n",
    "print(cluster_centers)\n",
    "\n",
    "# 군집별 top n 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명들을 반환함. \n",
    "def get_cluster_details(cluster_model, cluster_data, feature_names, clusters_num, top_n_features=10):\n",
    "    cluster_details = {}\n",
    "    \n",
    "    # cluster_centers array 의 값이 큰 순으로 정렬된 index 값을 반환\n",
    "    # 군집 중심점(centroid)별 할당된 word 피처들의 거리값이 큰 순으로 값을 구하기 위함.  \n",
    "    centroid_feature_ordered_ind = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
    "    \n",
    "    #개별 군집별로 iteration하면서 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명 입력\n",
    "    for cluster_num in range(clusters_num):\n",
    "        # 개별 군집별 정보를 담을 데이터 초기화. \n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
    "        \n",
    "        # cluster_centers_.argsort()[:,::-1] 로 구한 index 를 이용하여 top n 피처 단어를 구함. \n",
    "        top_feature_indexes = centroid_feature_ordered_ind[cluster_num, :top_n_features]\n",
    "        top_features = [ feature_names[ind] for ind in top_feature_indexes ]\n",
    "        \n",
    "        # top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함 \n",
    "        top_feature_values = cluster_model.cluster_centers_[cluster_num, top_feature_indexes].tolist()\n",
    "        \n",
    "        # cluster_details 딕셔너리 객체에 개별 군집별 핵심 단어와 중심위치 상대값, 그리고 해당 파일명 입력\n",
    "        cluster_details[cluster_num]['top_features'] = top_features\n",
    "        cluster_details[cluster_num]['top_features_value'] = top_feature_values\n",
    "        filenames = cluster_data[cluster_data['cluster_label'] == cluster_num]['filename']\n",
    "        filenames = filenames.values.tolist()\n",
    "        cluster_details[cluster_num]['filenames'] = filenames\n",
    "        \n",
    "    return cluster_details\n",
    "\n",
    "\n",
    "def print_cluster_details(cluster_details):\n",
    "    for cluster_num, cluster_detail in cluster_details.items():\n",
    "        print('####### Cluster {0}'.format(cluster_num))\n",
    "        print('Top features:', cluster_detail['top_features'])\n",
    "        print('Reviews 파일명 :',cluster_detail['filenames'][:7])\n",
    "        print('==================================================')\n",
    "\n",
    "\n",
    "feature_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\\\n",
    "                                  feature_names=feature_names, clusters_num=3, top_n_features=10 )\n",
    "print_cluster_details(cluster_details)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
